# Deep Learning Lab 02 - IT22267368

---

## Task 1: Backprop.ipynb

- Implements backpropagation from scratch for a simple neural network.
- Includes forward propagation, backward propagation, cost calculation, and weight updates.
- Demonstrates how hidden node count affects decision boundaries and accuracy.

---

## Task 2: NN_sample.ipynb

- A sample neural network example to understand the basic concepts of forward and backward passes.
- Useful for learning step-by-step neural network computation.
  
---

## Task 3: MLP_with_MNIST_dataset.ipynb

- Multi-Layer Perceptron (MLP) implementation for classifying the MNIST handwritten digits dataset.
- Hyperparameter tuning to improve accuracy.
- L1 & L2 regularization added to reduce overfitting.
- Confusion matrix visualization for class-wise performance analysis.
